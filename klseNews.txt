import requests
import mysql.connector
from bs4 import BeautifulSoup
import mysql.connector
from selenium import webdriver
from selenium.webdriver.common.keys import Keys

driver = webdriver.Chrome(executable_path="C:\DataMining\chromedriver.exe")
driver.implicitly_wait(40)
url = 'https://klse.i3investor.com/jsp/newshl.jsp'
driver.get(url)
innerHTML = driver.execute_script('return document.body.innerHTML')
soup = BeautifulSoup(innerHTML, 'lxml')
dates = soup.find("div", {"id": "container"}).find_all('h3')

for a in dates:
    date = a.text
    div = soup.find('h3', text = a.text).find_next_siblings('ul')[0]
    data = div.findAll('li')
    for b in data:
        title_tag = b.find('a')
        title = title_tag.text
        time_tag = b.find("span")
        time = time_tag.text
        print(date)
        print(title)
        print(time)

#(pls comment if no database)        
        mydb = mysql.connector.connect(
            host="localhost",
            user="root", 
            passwd="", 
            database="mds"
        )

        
        mycursor = mydb.cursor()

        sql = "INSERT INTO klsenews (date, title, author_time) VALUES (%s,%s,%s)"
        val = (date,title,time[3:])
        mycursor.execute(sql, val)

        mydb.commit()