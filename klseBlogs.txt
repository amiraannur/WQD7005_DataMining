import requests
import mysql.connector
from bs4 import BeautifulSoup
import mysql.connector

# Collect and parse first page
page = requests.get('https://klse.i3investor.com/jsp/blog/bloghl.jsp')
soup = BeautifulSoup(page.text, 'html.parser')
date = soup.find("div", {"id": "maincontent730"}).find_all('h3')
for a in date:
    print(" ")
    date = a.text
    div = soup.find('h3', text=a.text).find_next_siblings('ul')[0]
    data = div.findAll('li')
    print(data)
    for b in data:
        title_tag = b.find('a')
        title = title_tag.text
        author_time_tag = b.find("span")
        author_time = author_time_tag.text
        print(date)
        print(title)
        print(author_time)
      
#(pls comment if no database)  
        mydb = mysql.connector.connect(
            host="localhost",
            user="root", 
            passwd="", 
            database="mds"
        )
        
        mycursor = mydb.cursor()

        sql = "INSERT INTO klseblog (date, title, author_time) VALUES (%s,%s,%s)"
        val = (date,title,author_time[3:])
        mycursor.execute(sql, val)

        mydb.commit()  